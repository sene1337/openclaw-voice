<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenClaw Voice</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #fff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }
        
        .container {
            max-width: 600px;
            width: 100%;
            text-align: center;
        }
        
        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            background: linear-gradient(90deg, #ff6b35, #f7c94b);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        
        .subtitle {
            color: #888;
            margin-bottom: 40px;
        }
        
        .voice-button {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #ff6b35 0%, #e55a2b 100%);
            color: white;
            font-size: 1.2rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 40px rgba(255, 107, 53, 0.3);
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 30px;
        }
        
        .voice-button:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 50px rgba(255, 107, 53, 0.4);
        }
        
        .voice-button:active,
        .voice-button.listening {
            transform: scale(0.95);
            background: linear-gradient(135deg, #e55a2b 0%, #c44a22 100%);
        }
        
        .voice-button.listening {
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0%, 100% { box-shadow: 0 10px 40px rgba(255, 107, 53, 0.3); }
            50% { box-shadow: 0 10px 60px rgba(255, 107, 53, 0.6); }
        }
        
        .continuous-toggle {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 12px;
            margin-bottom: 20px;
        }
        
        .toggle-switch {
            position: relative;
            width: 56px;
            height: 30px;
        }
        
        .toggle-switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .toggle-slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: #333;
            border-radius: 30px;
            transition: 0.3s;
        }
        
        .toggle-slider:before {
            position: absolute;
            content: "";
            height: 22px;
            width: 22px;
            left: 4px;
            bottom: 4px;
            background: white;
            border-radius: 50%;
            transition: 0.3s;
        }
        
        .toggle-switch input:checked + .toggle-slider {
            background: #ff6b35;
        }
        
        .toggle-switch input:checked + .toggle-slider:before {
            transform: translateX(26px);
        }
        
        .toggle-label {
            font-weight: 600;
            color: #fff;
        }
        
        .toggle-hint {
            color: #666;
            font-size: 0.85rem;
        }
        
        .status {
            font-size: 1.1rem;
            color: #888;
            margin-bottom: 20px;
            min-height: 30px;
        }
        
        .status.active {
            color: #ff6b35;
        }
        
        .transcript-box {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
            text-align: left;
            min-height: 100px;
        }
        
        .transcript-box h3 {
            font-size: 0.9rem;
            color: #666;
            margin-bottom: 10px;
            text-transform: uppercase;
            letter-spacing: 0.1em;
        }
        
        .transcript-box p {
            font-size: 1rem;
            line-height: 1.6;
            color: #ccc;
        }
        
        .transcript-box p.user {
            color: #ff6b35;
        }
        
        .transcript-box p.assistant {
            color: #4fc3f7;
        }
        
        /* Markdown styling */
        .transcript-box code {
            background: rgba(255, 255, 255, 0.1);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'SF Mono', Monaco, monospace;
            font-size: 0.9em;
        }
        
        .transcript-box code.block {
            display: block;
            padding: 10px;
            margin: 8px 0;
            background: rgba(0, 0, 0, 0.3);
        }
        
        .transcript-box a {
            color: #ff6b35;
            text-decoration: none;
        }
        
        .transcript-box a:hover {
            text-decoration: underline;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }
        
        .controls button {
            padding: 10px 20px;
            border: 1px solid #444;
            background: transparent;
            color: #888;
            border-radius: 8px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: all 0.2s;
        }
        
        .controls button:hover {
            border-color: #ff6b35;
            color: #ff6b35;
        }
        
        .error {
            color: #ff4444;
            margin-top: 20px;
        }
        
        .instructions {
            margin-top: 40px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.03);
            border-radius: 12px;
            color: #666;
            font-size: 0.9rem;
        }
        
        .instructions code {
            background: rgba(255, 107, 53, 0.1);
            color: #ff6b35;
            padding: 2px 6px;
            border-radius: 4px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è OpenClaw Voice</h1>
        <p class="subtitle">Self-hosted voice AI interface</p>
        
        <button class="voice-button" id="voiceBtn">
            Hold to Talk
        </button>
        
        <div class="continuous-toggle">
            <label class="toggle-switch">
                <input type="checkbox" id="continuousMode">
                <span class="toggle-slider"></span>
            </label>
            <span class="toggle-label">Continuous Mode</span>
            <span class="toggle-hint">(hands-free, like Grok)</span>
        </div>
        
        <p class="status" id="status">Ready</p>
        
        <div class="transcript-box">
            <h3>Conversation</h3>
            <div id="transcript"></div>
        </div>
        
        <div class="controls">
            <button id="clearBtn">Clear History</button>
        </div>
        
        <p class="error" id="error"></p>
        
        <div class="instructions">
            <p><strong>Push-to-talk:</strong> Hold the button and speak. Release to send.</p>
            <p style="margin-top: 10px;"><strong>Continuous mode:</strong> Toggle ON for hands-free. Tap to start, it auto-listens after each response. Perfect for driving! üöó</p>
            <p style="margin-top: 10px;">Keyboard: <code>Space</code> to toggle recording.</p>
        </div>
        
        <footer style="margin-top: 40px; padding-top: 20px; border-top: 1px solid #333; font-size: 0.8rem; color: #555;">
            <p>Built with ü¶Ä by <a href="https://purplehorizons.io" target="_blank" style="color: #888; text-decoration: none;">Purple Horizons</a></p>
            <p style="margin-top: 5px;"><a href="https://github.com/Purple-Horizons/openclaw-voice" target="_blank" style="color: #666; text-decoration: none;">GitHub</a> ¬∑ <a href="https://openclaw.ai" target="_blank" style="color: #666; text-decoration: none;">OpenClaw</a></p>
        </footer>
    </div>

    <script>
        const voiceBtn = document.getElementById('voiceBtn');
        const statusEl = document.getElementById('status');
        const transcriptEl = document.getElementById('transcript');
        const errorEl = document.getElementById('error');
        const clearBtn = document.getElementById('clearBtn');
        const continuousModeToggle = document.getElementById('continuousMode');
        
        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;
        let audioSource = null;
        let audioProcessor = null;
        let mediaStream = null;
        let isRecording = false;
        let continuousMode = false;
        let silenceTimer = null;
        let silenceThreshold = 1500; // ms of silence before stopping
        
        // Get API key from URL params or localStorage
        function getApiKey() {
            const urlParams = new URLSearchParams(window.location.search);
            return urlParams.get('api_key') || localStorage.getItem('openclaw_api_key') || '';
        }
        
        // Connect to WebSocket
        function connect() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const apiKey = getApiKey();
            // Support serving from subdirectory (e.g., /voice)
            const basePath = window.location.pathname.replace(/\/$/, '');
            const wsPath = basePath ? `${basePath}/ws` : '/ws';
            const wsUrl = apiKey 
                ? `${protocol}//${window.location.host}${wsPath}?api_key=${apiKey}`
                : `${protocol}//${window.location.host}${wsPath}`;
            
            ws = new WebSocket(wsUrl);
            
            ws.onopen = () => {
                setStatus('Connected');
                errorEl.textContent = '';
            };
            
            ws.onclose = (event) => {
                if (event.code === 4001) {
                    setStatus('‚ùå API key required');
                    errorEl.textContent = 'This server requires an API key. Add ?api_key=YOUR_KEY to the URL.';
                } else if (event.code === 4002) {
                    setStatus('‚ùå Invalid API key');
                    errorEl.textContent = 'Your API key is invalid or expired.';
                } else if (event.code === 4003) {
                    setStatus('‚ùå Rate limited');
                    errorEl.textContent = 'Too many requests. Please wait and try again.';
                } else {
                    setStatus('Disconnected - reconnecting...');
                    setTimeout(connect, 2000);
                }
            };
            
            ws.onerror = (e) => {
                errorEl.textContent = 'WebSocket error. Is the server running?';
            };
            
            ws.onmessage = (event) => {
                const msg = JSON.parse(event.data);
                handleMessage(msg);
            };
        }
        
        // Audio queue for streaming playback
        let audioQueue = [];
        let isPlayingQueue = false;
        let currentResponseElement = null;
        let streamingText = '';
        
        function handleMessage(msg) {
            switch (msg.type) {
                case 'listening_started':
                    setStatus(continuousMode ? 'üéôÔ∏è Listening (continuous)...' : 'Listening...', true);
                    break;
                case 'listening_stopped':
                    setStatus('Processing...');
                    break;
                case 'transcript':
                    addTranscript('You', msg.text, 'user');
                    setStatus('Getting response...');
                    // Reset streaming state
                    streamingText = '';
                    currentResponseElement = null;
                    audioQueue = [];
                    break;
                case 'response_text':
                    // Legacy non-streaming response
                    addTranscript('AI', msg.text, 'assistant');
                    break;
                case 'response_chunk':
                    // Streaming text chunk
                    streamingText += msg.text;
                    updateStreamingTranscript(streamingText);
                    setStatus('Speaking...', true);
                    break;
                case 'audio_chunk':
                    // Queue audio chunk for playback
                    queueAudioChunk(msg.data, msg.sample_rate);
                    break;
                case 'response_complete':
                    // Finalize the response
                    if (currentResponseElement) {
                        currentResponseElement.innerHTML = `<strong>AI:</strong> ${renderMarkdown(msg.text)}`;
                    }
                    break;
                case 'audio_response':
                    // Legacy non-streaming audio
                    playAudioWithCallback(msg.data, msg.sample_rate, onAudioComplete);
                    setStatus('Speaking...');
                    break;
                case 'pong':
                    break;
            }
        }
        
        function updateStreamingTranscript(text) {
            if (!currentResponseElement) {
                currentResponseElement = document.createElement('p');
                currentResponseElement.className = 'assistant';
                transcriptEl.appendChild(currentResponseElement);
            }
            currentResponseElement.innerHTML = `<strong>AI:</strong> ${renderMarkdown(text)}`;
            transcriptEl.scrollTop = transcriptEl.scrollHeight;
        }
        
        function queueAudioChunk(base64Data, sampleRate) {
            audioQueue.push({ data: base64Data, sampleRate });
            if (!isPlayingQueue) {
                playNextInQueue();
            }
        }
        
        // Shared playback AudioContext (browsers limit concurrent contexts)
        let playbackCtx = null;
        function getPlaybackCtx(sampleRate) {
            if (!playbackCtx || playbackCtx.state === 'closed') {
                playbackCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate });
            }
            if (playbackCtx.state === 'suspended') {
                playbackCtx.resume();
            }
            return playbackCtx;
        }
        
        async function playNextInQueue() {
            if (audioQueue.length === 0) {
                isPlayingQueue = false;
                onAudioComplete();
                return;
            }
            
            isPlayingQueue = true;
            const { data, sampleRate } = audioQueue.shift();
            
            try {
                // Decode base64 to PCM
                const binaryString = atob(data);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // Convert Int16 PCM to Float32
                const int16 = new Int16Array(bytes.buffer);
                const float32 = new Float32Array(int16.length);
                for (let i = 0; i < int16.length; i++) {
                    float32[i] = int16[i] / 32768.0;
                }
                
                if (!playbackCtx || playbackCtx.state === 'closed') {
                    playbackCtx = new (window.AudioContext || window.webkitAudioContext)();
                }
                if (playbackCtx.state === 'suspended') {
                    await playbackCtx.resume();
                }
                const buffer = playbackCtx.createBuffer(1, float32.length, sampleRate);
                buffer.copyToChannel(float32, 0);
                
                const source = playbackCtx.createBufferSource();
                source.buffer = buffer;
                source.connect(playbackCtx.destination);
                source.onended = () => playNextInQueue();
                source.start(0);
                console.log(`Playing chunk: ${float32.length} samples, state=${playbackCtx.state}, max=${Math.max(...float32.slice(0,100).map(Math.abs)).toFixed(3)}`);
            } catch (e) {
                console.error('Audio playback error:', e);
                playNextInQueue();
            }
        }
        
        function onAudioComplete() {
            if (continuousMode) {
                setStatus('üéôÔ∏è Ready to listen...', true);
                setTimeout(() => {
                    if (continuousMode) startRecording();
                }, 300);
            } else {
                setStatus('Ready');
            }
        }
        
        function setStatus(text, active = false) {
            statusEl.textContent = text;
            statusEl.className = active ? 'status active' : 'status';
        }
        
        function addTranscript(speaker, text, className) {
            const p = document.createElement('p');
            p.className = className;
            // Render markdown for assistant responses
            const renderedText = className === 'assistant' ? renderMarkdown(text) : escapeHtml(text);
            p.innerHTML = `<strong>${speaker}:</strong> ${renderedText}`;
            transcriptEl.appendChild(p);
            transcriptEl.scrollTop = transcriptEl.scrollHeight;
        }
        
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
        
        function renderMarkdown(text) {
            // Simple markdown renderer
            return text
                // Code blocks
                .replace(/```[\s\S]*?```/g, '<code class="block">code</code>')
                // Inline code
                .replace(/`([^`]+)`/g, '<code>$1</code>')
                // Bold
                .replace(/\*\*([^*]+)\*\*/g, '<strong>$1</strong>')
                // Italic
                .replace(/\*([^*]+)\*/g, '<em>$1</em>')
                // Headers (convert to bold)
                .replace(/^#{1,3}\s+(.+)$/gm, '<strong>$1</strong>')
                // Links
                .replace(/\[([^\]]+)\]\(([^)]+)\)/g, '<a href="$2" target="_blank">$1</a>')
                // Line breaks
                .replace(/\n/g, '<br>');
        }
        
        // Audio recording
        async function startRecording() {
            if (isRecording) return;
            
            try {
                // Reuse stream if available, otherwise get new one
                if (!mediaStream) {
                    mediaStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true,
                        }
                    });
                }
                
                audioContext = new AudioContext();  // Use native sample rate (Safari ignores 16kHz)
                console.log('AudioContext sample rate:', audioContext.sampleRate);
                audioSource = audioContext.createMediaStreamSource(mediaStream);
                
                let lastSoundTime = Date.now();
                
                let audioChunkCount = 0;
                const sendAudio = (audioData) => {
                    if (isRecording && ws && ws.readyState === WebSocket.OPEN) {
                        audioChunkCount++;
                        const maxVal = Math.max(...Array.from(audioData).map(Math.abs));
                        if (audioChunkCount <= 5 || audioChunkCount % 20 === 0) {
                            console.log(`Audio chunk #${audioChunkCount}: ${audioData.length} samples, max=${maxVal.toFixed(6)}, rate=${audioContext.sampleRate}`);
                        }
                        const base64 = float32ToBase64(audioData);
                        ws.send(JSON.stringify({ type: 'audio', data: base64, sample_rate: audioContext.sampleRate }));
                        if (continuousMode) {
                            const energy = audioData.reduce((sum, val) => sum + Math.abs(val), 0) / audioData.length;
                            if (energy > 0.01) {
                                lastSoundTime = Date.now();
                            } else if (Date.now() - lastSoundTime > silenceThreshold) {
                                stopRecording();
                            }
                        }
                    }
                };
                
                // Try AudioWorklet (Chrome/modern), fall back to ScriptProcessor (Safari)
                if (audioContext.audioWorklet) {
                    try {
                        const workletCode = `
                            class AudioSender extends AudioWorkletProcessor {
                                constructor() {
                                    super();
                                    this.buffer = new Float32Array(4096);
                                    this.offset = 0;
                                }
                                process(inputs) {
                                    const input = inputs[0];
                                    if (input.length > 0 && input[0].length > 0) {
                                        const data = input[0];
                                        for (let i = 0; i < data.length; i++) {
                                            this.buffer[this.offset++] = data[i];
                                            if (this.offset >= 4096) {
                                                this.port.postMessage(new Float32Array(this.buffer));
                                                this.offset = 0;
                                            }
                                        }
                                    }
                                    return true;
                                }
                            }
                            registerProcessor('audio-sender', AudioSender);
                        `;
                        const blob = new Blob([workletCode], { type: 'application/javascript' });
                        const url = URL.createObjectURL(blob);
                        await audioContext.audioWorklet.addModule(url);
                        URL.revokeObjectURL(url);
                        
                        audioProcessor = new AudioWorkletNode(audioContext, 'audio-sender');
                        audioProcessor.port.onmessage = (e) => sendAudio(e.data);
                        audioSource.connect(audioProcessor);
                        audioProcessor.connect(audioContext.destination);
                        console.log('Using AudioWorklet for mic capture');
                    } catch (workletErr) {
                        console.warn('AudioWorklet failed, falling back:', workletErr);
                        audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                        audioProcessor.onaudioprocess = (e) => sendAudio(e.inputBuffer.getChannelData(0));
                        audioSource.connect(audioProcessor);
                        audioProcessor.connect(audioContext.destination);
                    }
                } else {
                    // Safari fallback
                    audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                    audioProcessor.onaudioprocess = (e) => sendAudio(e.inputBuffer.getChannelData(0));
                    audioSource.connect(audioProcessor);
                    audioProcessor.connect(audioContext.destination);
                    console.log('Using ScriptProcessor for mic capture (Safari)');
                }
                
                // Pre-create playback context during user gesture (Safari requires this)
                if (!playbackCtx || playbackCtx.state === 'closed') {
                    playbackCtx = new (window.AudioContext || window.webkitAudioContext)();
                    console.log('Created playback context during user gesture, state:', playbackCtx.state);
                }
                if (playbackCtx.state === 'suspended') {
                    await playbackCtx.resume();
                    console.log('Resumed playback context, state:', playbackCtx.state);
                }
                
                isRecording = true;
                voiceBtn.classList.add('listening');
                voiceBtn.textContent = continuousMode ? 'üéôÔ∏è Listening...' : 'Listening...';
                
                ws.send(JSON.stringify({ type: 'start_listening' }));
                
            } catch (err) {
                errorEl.textContent = `Microphone error: ${err.message}`;
            }
        }
        
        function stopRecording() {
            if (!isRecording) return;
            
            isRecording = false;
            voiceBtn.classList.remove('listening');
            voiceBtn.textContent = continuousMode ? 'Tap to Talk' : 'Hold to Talk';
            
            // Disconnect processor but keep stream for continuous mode
            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }
            if (audioSource) {
                audioSource.disconnect();
                audioSource = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            // Only release stream if not in continuous mode
            if (!continuousMode && mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'stop_listening' }));
            }
        }
        
        // Audio playback
        function playAudio(base64Data, sampleRate) {
            playAudioWithCallback(base64Data, sampleRate, null);
        }
        
        function playAudioWithCallback(base64Data, sampleRate, callback) {
            const ctx = getPlaybackCtx(sampleRate);
            // Legacy path sends Float32 directly
            const audioData = base64ToFloat32(base64Data);
            const buffer = ctx.createBuffer(1, audioData.length, sampleRate);
            buffer.getChannelData(0).set(audioData);
            
            const source = ctx.createBufferSource();
            source.buffer = buffer;
            source.connect(ctx.destination);
            
            if (callback) {
                source.onended = callback;
            }
            
            source.start();
        }
        
        // Utilities
        function float32ToBase64(float32Array) {
            const bytes = new Uint8Array(float32Array.buffer);
            let binary = '';
            for (let i = 0; i < bytes.length; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }
        
        function base64ToFloat32(base64) {
            const binary = atob(base64);
            const bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) {
                bytes[i] = binary.charCodeAt(i);
            }
            return new Float32Array(bytes.buffer);
        }
        
        // Event listeners
        voiceBtn.addEventListener('mousedown', () => {
            if (!continuousMode) startRecording();
        });
        voiceBtn.addEventListener('mouseup', () => {
            if (!continuousMode) stopRecording();
        });
        voiceBtn.addEventListener('mouseleave', () => {
            if (!continuousMode) stopRecording();
        });
        voiceBtn.addEventListener('touchstart', (e) => { 
            e.preventDefault(); 
            if (!continuousMode) startRecording();
        });
        voiceBtn.addEventListener('touchend', () => {
            if (!continuousMode) stopRecording();
        });
        
        // Tap for continuous mode
        voiceBtn.addEventListener('click', () => {
            if (continuousMode) {
                if (isRecording) {
                    stopRecording();
                } else {
                    startRecording();
                }
            }
        });
        
        // Spacebar to toggle
        document.addEventListener('keydown', (e) => {
            if (e.code === 'Space' && !e.repeat) {
                e.preventDefault();
                if (isRecording) {
                    stopRecording();
                } else {
                    startRecording();
                }
            }
        });
        
        clearBtn.addEventListener('click', () => {
            transcriptEl.innerHTML = '';
        });
        
        // Continuous mode toggle
        continuousModeToggle.addEventListener('change', (e) => {
            continuousMode = e.target.checked;
            voiceBtn.textContent = continuousMode ? 'Tap to Talk' : 'Hold to Talk';
            
            if (continuousMode) {
                setStatus('üéôÔ∏è Continuous mode ON ‚Äî tap to start', true);
                // Pre-request mic permission
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => { mediaStream = stream; })
                    .catch(err => { errorEl.textContent = `Mic access needed: ${err.message}`; });
            } else {
                setStatus('Ready');
                // Release mic
                if (mediaStream && !isRecording) {
                    mediaStream.getTracks().forEach(track => track.stop());
                    mediaStream = null;
                }
            }
        });
        
        // Connect on load
        connect();
        
        // Keep connection alive
        setInterval(() => {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'ping' }));
            }
        }, 30000);
    </script>
</body>
</html>
